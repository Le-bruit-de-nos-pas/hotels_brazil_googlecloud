{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_city_chanel_combin_extract  = pd.read_csv('c:\\\\Users\\\\paulo\\\\Desktop\\\\hotels brazil\\\\data\\\\other\\\\hotel_city_chanel_combin_extract.csv')\n",
    "hotel_city_chanel_combin_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_city_chanel_combin_extract.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_city_chanel_combin_extract['Hotel_ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unseen_hotels(df, canal_id):\n",
    "    # Ensure canal_id is an integer\n",
    "    if not isinstance(canal_id, int):\n",
    "        raise ValueError(f\"Expected an integer for canal_id, but got {type(canal_id)}.\")\n",
    "\n",
    "    # Get the Cidade_IDs corresponding to the given Canal_ID\n",
    "    cidade_ids = df.loc[df['Canal_ID'] == canal_id, 'Cidade_ID'].unique()\n",
    "\n",
    "    # Get all Hotel_IDs in the corresponding Cidade_IDs\n",
    "    hotels_in_cidade = df.loc[df['Cidade_ID'].isin(cidade_ids), 'Hotel_ID'].unique()\n",
    "\n",
    "    # Get the Hotel_IDs already associated with the given Canal_ID\n",
    "    seen_hotels = df.loc[df['Canal_ID'] == canal_id, 'Hotel_ID'].unique()\n",
    "\n",
    "    # Filter out seen hotels\n",
    "    unseen_hotels = [hotel for hotel in hotels_in_cidade if hotel not in seen_hotels]\n",
    "\n",
    "    # Return unseen hotels as a DataFrame column, ensuring uniqueness\n",
    "    unseen_hotels_df = pd.DataFrame({'Unseen_Hotel_ID': unseen_hotels}).drop_duplicates()\n",
    "\n",
    "    return unseen_hotels_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "get_unseen_hotels(hotel_city_chanel_combin_extract, 1245)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_city_chanel_combin_extract[hotel_city_chanel_combin_extract['Canal_ID']==1245].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_city_chanel_combin_extract[hotel_city_chanel_combin_extract['Canal_ID']==1245]['Cidade_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_city_chanel_combin_extract.groupby('Canal_ID').size().reset_index(name='Counts').sort_values(by='Counts', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "get_unseen_hotels(hotel_city_chanel_combin_extract, 1026)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_city_chanel_combin_extract[hotel_city_chanel_combin_extract['Cidade_ID']==4464157.0]['Hotel_ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_city_chanel_combin_extract[hotel_city_chanel_combin_extract['Canal_ID'] == 124]['Hotel_ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_city_chanel_combin_extract[(hotel_city_chanel_combin_extract['Canal_ID'] == 124) & (hotel_city_chanel_combin_extract['Cidade_ID'] == 1571478)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lake_prd_314410_cz_hoteis_canais_combinations  = pd.read_csv('c:\\\\Users\\\\paulo\\\\Desktop\\\\hotels brazil\\\\data\\\\lookups\\\\data-lake-prd-314410.cz.hoteis_canais_combinations.csv')\n",
    "data_lake_prd_314410_cz_hoteis_canais_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the 'distinct_combinations' column into two separate columns\n",
    "data_lake_prd_314410_cz_hoteis_canais_combinations[['Hotel_ID', 'Canal_ID']] = data_lake_prd_314410_cz_hoteis_canais_combinations['distinct_combinations'].str.split('-', expand=True)\n",
    "\n",
    "# Convert the new columns to integers\n",
    "data_lake_prd_314410_cz_hoteis_canais_combinations['Hotel_ID'] = data_lake_prd_314410_cz_hoteis_canais_combinations['Hotel_ID'].astype(int)\n",
    "data_lake_prd_314410_cz_hoteis_canais_combinations['Canal_ID'] = data_lake_prd_314410_cz_hoteis_canais_combinations['Canal_ID'].astype(int)\n",
    "\n",
    "# Drop the original 'distinct_combinations' column\n",
    "data_lake_prd_314410_cz_hoteis_canais_combinations.drop(columns=['distinct_combinations'], inplace=True)\n",
    "data_lake_prd_314410_cz_hoteis_canais_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lake_prd_314410_cz_hoteis = pd.read_csv('c:\\\\Users\\\\paulo\\\\Desktop\\\\hotels brazil\\\\data\\\\lookups\\\\data-lake-prd-314410.cz.hoteis.csv')\n",
    "data_lake_prd_314410_cz_hoteis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lisbon_hotels = data_lake_prd_314410_cz_hoteis[data_lake_prd_314410_cz_hoteis['Cidade_ID']==509072]['Hotel_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lisbon_hotels.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lake_prd_314410_cz_hoteis = data_lake_prd_314410_cz_hoteis[['Hotel_ID', 'Estrelas', 'Quartos', 'CategoriaHotel', 'Moeda', 'Cidade_ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lake_prd_314410_cz_hoteis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lake_prd_314410_cz_cidades = pd.read_csv('c:\\\\Users\\\\paulo\\\\Desktop\\\\hotels brazil\\\\data\\\\lookups\\\\data-lake-prd-314410.cz.cidades.csv')\n",
    "data_lake_prd_314410_cz_cidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lake_prd_314410_cz_cidades = data_lake_prd_314410_cz_cidades[['Cidade_ID', 'Pais']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(data_lake_prd_314410_cz_hoteis, \n",
    "                       data_lake_prd_314410_cz_cidades, \n",
    "                       on='Cidade_ID', \n",
    "                       how='left')\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_counts = merged_data.groupby('Pais').size().reset_index(name='Counts').sort_values(by='Counts', ascending=False)\n",
    "print(country_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_counts['Counts'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "19397/19650  # 1.3% of the hotels cannot be mapped to a country ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.dropna(subset=['Pais'], inplace=True)\n",
    "merged_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.drop(columns=['Cidade_ID'], inplace=True)\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lake_prd_314410_cz_pull_pesquisas_average_price_hotel_currency = pd.read_csv('c:\\\\Users\\\\paulo\\\\Desktop\\\\hotels brazil\\\\data\\\\other\\\\data-lake-prd-314410.cz.pull-pesquisas_average_price_hotel_currency.csv')\n",
    "data_lake_prd_314410_cz_moedas = pd.read_csv('c:\\\\Users\\\\paulo\\\\Desktop\\\\hotels brazil\\\\data\\\\lookups\\\\data-lake-prd-314410.cz.moedas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform left join\n",
    "data_lake_prd_314410_cz_pull_pesquisas_average_price_hotel_currency = pd.merge(data_lake_prd_314410_cz_pull_pesquisas_average_price_hotel_currency, \n",
    "                     data_lake_prd_314410_cz_moedas[['Moeda_ID', 'Cotacao_USD']], \n",
    "                     on='Moeda_ID', \n",
    "                     how='left')\n",
    "\n",
    "# Display the merged dataframe\n",
    "print(data_lake_prd_314410_cz_pull_pesquisas_average_price_hotel_currency.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lake_prd_314410_cz_pull_pesquisas_average_price_hotel_currency['weighted_mean_diaria_usd'] = \\\n",
    "    data_lake_prd_314410_cz_pull_pesquisas_average_price_hotel_currency['weighted_mean_diaria'] * \\\n",
    "        data_lake_prd_314410_cz_pull_pesquisas_average_price_hotel_currency['Cotacao_USD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lake_prd_314410_cz_pull_pesquisas_average_price_hotel_currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(merged_data, \n",
    "                     data_lake_prd_314410_cz_pull_pesquisas_average_price_hotel_currency[['Hotel_ID', 'Cotacao_USD', 'weighted_mean_diaria_usd']], \n",
    "                     on='Hotel_ID', \n",
    "                     how='left')\n",
    "\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lake_prd_314410_cz_pull_pesquisas_estadia_x_reservas_volume = pd.read_csv('c:\\\\Users\\\\paulo\\\\Desktop\\\\hotels brazil\\\\data\\\\other\\\\data-lake-prd-314410.cz.pull-pesquisas_estadia_x_reservas_volume.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lake_prd_314410_cz_pull_pesquisas_estadia_x_reservas_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(merged_data, \n",
    "                     data_lake_prd_314410_cz_pull_pesquisas_estadia_x_reservas_volume, \n",
    "                     on='Hotel_ID', \n",
    "                     how='left')\n",
    "\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lake_prd_314410_cz_pull_pesquisas_estadia_x_reservas_x_price_receitas = pd.read_csv('c:\\\\Users\\\\paulo\\\\Desktop\\\\hotels brazil\\\\data\\\\other\\\\data-lake-prd-314410.cz.pull-pesquisas_estadia_x_reservas_x_price_receitas.csv')\n",
    "data_lake_prd_314410_cz_pull_pesquisas_estadia_x_reservas_x_price_receitas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(merged_data, \n",
    "                     data_lake_prd_314410_cz_pull_pesquisas_estadia_x_reservas_x_price_receitas, \n",
    "                     on='Hotel_ID', \n",
    "                     how='left')\n",
    "\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data['total_reservas_estadia_diaria'] = \\\n",
    "    merged_data['total_reservas_estadia_diaria'] * \\\n",
    "        merged_data['Cotacao_USD']\n",
    "\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.drop(columns=['Moeda'], inplace=True)\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.drop(columns=['Cotacao_USD'], inplace=True)\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.dropna(inplace=True)\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant columns\n",
    "numerical_cols = ['Estrelas', 'Quartos', 'weighted_mean_diaria_usd', \n",
    "                  'total_reservas_estadia', 'total_reservas_estadia_diaria']\n",
    "categorical_cols = ['CategoriaHotel', 'Pais']\n",
    "\n",
    "# Normalize numerical variables\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(merged_data[numerical_cols])\n",
    "\n",
    "# Encode categorical variables\n",
    "data_encoded = pd.get_dummies(merged_data[categorical_cols], drop_first=True)\n",
    "\n",
    "# Combine normalized and encoded data\n",
    "data_final = pd.concat([pd.DataFrame(data_scaled, columns=numerical_cols), data_encoded.reset_index(drop=True)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine optimal number of clusters using the elbow method\n",
    "wcss = []\n",
    "for i in range(2, 10):\n",
    "    kmeans = KMeans(n_clusters=i, random_state=42)\n",
    "    kmeans.fit(data_final)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "plt.plot(range(2, 10), wcss, marker='o')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.title('Elbow Method')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose optimal number of clusters (e.g., k=4)\n",
    "kmeans = KMeans(n_clusters=10, random_state=42)\n",
    "merged_data['Cluster'] = kmeans.fit_predict(data_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze contributions using PCA\n",
    "pca = PCA(n_components=10)\n",
    "pca_data = pca.fit_transform(data_final)\n",
    "plt.scatter(pca_data[:, 2], pca_data[:, 3], c=merged_data['Cluster'], cmap='viridis')\n",
    "plt.title('PCA of Clusters')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze cluster centroids\n",
    "cluster_centers = pd.DataFrame(kmeans.cluster_centers_, columns=data_final.columns)\n",
    "important_vars = cluster_centers.T\n",
    "important_vars.columns = [f'Cluster_{i}' for i in range(10)]\n",
    "print(important_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_export.to_csv('c:\\\\Users\\\\paulo\\\\Desktop\\\\hotels brazil\\\\data\\\\other\\\\clusters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def preprocess_data(data):\n",
    "    \"\"\"\n",
    "    Preprocess the data to create a numerical feature matrix.\n",
    "    - Scales numerical columns\n",
    "    - One-hot encodes categorical columns\n",
    "    - Converts boolean columns to numerical\n",
    "    \"\"\"\n",
    "    # Define column groups\n",
    "    numerical_cols = ['Estrelas', 'Quartos', 'weighted_mean_diaria_usd', \n",
    "                      'total_reservas_estadia', 'total_reservas_estadia_diaria']\n",
    "    categorical_cols = ['CategoriaHotel', 'Pais']\n",
    "    boolean_cols = data.select_dtypes(include=['bool']).columns.tolist()\n",
    "    \n",
    "    # Convert boolean columns to integers\n",
    "    data[boolean_cols] = data[boolean_cols].astype(int)\n",
    "    \n",
    "    # Scale numerical columns\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(data[numerical_cols])\n",
    "    data_scaled_df = pd.DataFrame(data_scaled, columns=numerical_cols, index=data.index)\n",
    "    \n",
    "    # One-hot encode categorical columns\n",
    "    data_encoded = pd.get_dummies(data[categorical_cols], drop_first=True)\n",
    "    \n",
    "    # Combine scaled numerical, one-hot encoded categorical, and boolean features\n",
    "    features = pd.concat([data_scaled_df, data_encoded, data[boolean_cols]], axis=1)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def rank_similar_hotels(hotel_id, data, features, metric='euclidean'):\n",
    "    \"\"\"\n",
    "    Rank hotels based on similarity to a given Hotel_ID.\n",
    "    \"\"\"\n",
    "    # Check if the Hotel_ID exists\n",
    "    if hotel_id not in data['Hotel_ID'].values:\n",
    "        raise ValueError(f\"Hotel_ID {hotel_id} not found in the dataset.\")\n",
    "    \n",
    "    # Get the index of the given Hotel_ID\n",
    "    idx = data.index[data['Hotel_ID'] == hotel_id][0]\n",
    "    \n",
    "    # Compute pairwise distances\n",
    "    distances = cdist([features.iloc[idx]], features, metric=metric)[0]\n",
    "    \n",
    "    # Add distances to the original dataset\n",
    "    data_copy = data.copy()\n",
    "    data_copy['Similarity'] = distances\n",
    "    \n",
    "    # Sort by similarity and return ranked hotels\n",
    "    ranked = data_copy.sort_values('Similarity').reset_index(drop=True)\n",
    "    return ranked[['Hotel_ID', 'Similarity']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_similar_hotels_cosine(hotel_id, data, features):\n",
    "    \"\"\"\n",
    "    Rank hotels based on cosine similarity to a given Hotel_ID.\n",
    "    \"\"\"\n",
    "    # Ensure the Hotel_ID exists\n",
    "    if hotel_id not in data['Hotel_ID'].values:\n",
    "        raise ValueError(f\"Hotel_ID {hotel_id} not found in the dataset.\")\n",
    "    \n",
    "    # Get the index of the given Hotel_ID\n",
    "    idx = data.index[data['Hotel_ID'] == hotel_id][0]\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    similarity_scores = cosine_similarity([features.iloc[idx]], features)[0]\n",
    "    \n",
    "    # Add similarity scores to the original dataset\n",
    "    data_copy = data.copy()\n",
    "    data_copy['Similarity'] = similarity_scores\n",
    "    \n",
    "    # Sort by similarity and return ranked results\n",
    "    ranked = data_copy.sort_values('Similarity', ascending=False).reset_index(drop=True)\n",
    "    return ranked[['Hotel_ID', 'Similarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Data\n",
    "data = merged_data\n",
    "\n",
    "# Step 1: Preprocess the data\n",
    "features = preprocess_data(data)\n",
    "\n",
    "# Step 2: Rank hotels similar to Hotel_ID 3728 using cosine similarity\n",
    "ranked_hotels = rank_similar_hotels_cosine(3728, data, features)\n",
    "\n",
    "# Step 3: Print results\n",
    "print(ranked_hotels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data[merged_data['Hotel_ID'].isin([3328, 9385, 17731])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data[merged_data['Cluster'].isin([0])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
