{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Personalized Ranking (BPR)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Bayesian Personalized Ranking (BPR) is a popular recommendation system technique based on **matrix factorization**. It focuses on the **relative ranking** of items for a given user rather than absolute ratings. BPR is especially suitable for **implicit feedback data**, such as clicks, purchases, or views, where explicit ratings (e.g., 1-5 stars) are not available.\n",
    "\n",
    "### Key Characteristics:\n",
    "- **Implicit feedback**: BPR works on implicit data (e.g., clicks, views, purchases), rather than explicit ratings.\n",
    "- **Pairwise ranking**: It optimizes the system to predict which items are more likely to be preferred by a user, rather than predicting an exact score.\n",
    "- **Matrix factorization**: BPR decomposes the user-item interaction matrix into lower-dimensional matrices to learn user and item latent factors.\n",
    "\n",
    "## The BPR Model\n",
    "\n",
    "BPR is based on a **probabilistic** framework and aims to rank items such that more relevant items are ranked higher. The core idea is to model the relative preference between pairs of items, where a user is assumed to prefer one item over another.\n",
    "\n",
    "### Assumptions:\n",
    "- Users (hotels) interact with some subset of items (e.g., channels).\n",
    "- Each hotel has \"preferences\" for channels that are not directly observable, but they can be inferred from past interactions.\n",
    "- For each hotel, the model learns two latent vectors: one for the hotel and one for the channel.\n",
    "\n",
    "### Objective:\n",
    "For each hotel (user) `u` and for each **pair of items** `(i, j)`, the objective is to maximize the likelihood that the user prefers item `i` over item `j`, if the user has interacted with `i` but not `j`.\n",
    "\n",
    "### Matrix Factorization:\n",
    "We assume that the user-item interaction matrix `R` is sparse, with only some interactions observed. BPR seeks to factorize this matrix into two low-rank matrices:\n",
    "\n",
    "- **User matrix** `U`: An $M \\times K$ matrix, where $M$ is the number of users, and $K$ is the number of latent factors.\n",
    "- **Item matrix** `V`: An $N \\times K$ matrix, where $N$ is the number of items, and $K$ is the number of latent factors.\n",
    "\n",
    "The latent factor vectors are learned by the algorithm for both users and items in the matrix factorization model.\n",
    "\n",
    "## BPR Loss Function\n",
    "\n",
    "The BPR model uses a **pairwise ranking loss function**. Given a user `u`, a positively interacted item `i`, and a negatively interacted item `j`, the loss function aims to **maximize the difference** between the score for `i` and `j`:\n",
    "\n",
    "$$\n",
    "L_{BPR} = -\\sum_{(u, i, j)} \\log(\\sigma(x_{ui} - x_{uj}))\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $ \\sigma(x) $ is the **sigmoid function**, which maps any real-valued number into a range between 0 and 1:\n",
    "  $$\n",
    "  \\sigma(x) = \\frac{1}{1 + e^{-x}}\n",
    "  $$\n",
    "- $x_{ui} = U_u^T V_i$ is the predicted score for user `u` and item `i` based on their latent factor vectors.\n",
    "- $ x_{uj} = U_u^T V_j $ is the predicted score for user `u` and item `j`.\n",
    "- The sum is taken over all observed interactions where the user `u` has interacted with item `i` and not item `j`.\n",
    "\n",
    "The goal is to **maximize** the log-likelihood that the user prefers item `i` over item `j` (i.e., $ x_{ui} - x_{uj} > 0 $).\n",
    "\n",
    "### Regularization:\n",
    "To prevent overfitting, **L2 regularization** is applied to the latent factors $ U_u $ and $ V_i $ to ensure that the model does not assign excessively large values to the latent factors. The regularization term is:\n",
    "\n",
    "$$\n",
    "L_{reg} = \\lambda \\left( \\| U_u \\|^2 + \\| V_i \\|^2 + \\| V_j \\|^2 \\right)\n",
    "$$\n",
    "\n",
    "Where $ \\lambda $ is a regularization parameter.\n",
    "\n",
    "Thus, the final loss function to minimize is:\n",
    "\n",
    "$$\n",
    "L_{total} = L_{BPR} + L_{reg}\n",
    "$$\n",
    "\n",
    "Where $ L_{BPR} $ is the pairwise ranking loss, and $ L_{reg} $ is the regularization term.\n",
    "\n",
    "## Training the Model\n",
    "\n",
    "### Optimization:\n",
    "The loss function is minimized using a **stochastic gradient descent (SGD)** approach. For each pair `(i, j)` of items for each user `u`, the gradients of the loss function with respect to the latent factors $ U_u $ and $ V_i $ are computed and used to update the factors:\n",
    "\n",
    "$$\n",
    "U_u \\leftarrow U_u - \\eta \\frac{\\partial L_{total}}{\\partial U_u}\n",
    "$$\n",
    "$$\n",
    "V_i \\leftarrow V_i - \\eta \\frac{\\partial L_{total}}{\\partial V_i}\n",
    "$$\n",
    "$$\n",
    "V_j \\leftarrow V_j - \\eta \\frac{\\partial L_{total}}{\\partial V_j}\n",
    "$$\n",
    "\n",
    "Where $ \\eta $ is the learning rate.\n",
    "\n",
    "### Iterations:\n",
    "The training continues for a pre-defined number of iterations (e.g., 5000 iterations), and the model converges when the loss function stops improving.\n",
    "\n",
    "## Inference (Making Recommendations)\n",
    "\n",
    "After training, to make recommendations for a user `u`, the model computes the scores for all items based on the learned latent factors:\n",
    "\n",
    "$$\n",
    "\\hat{r}_{ui} = U_u^T V_i\n",
    "$$\n",
    "\n",
    "Then, the top-N items with the highest predicted scores are recommended to the user. These items have the highest likelihood of being preferred by the user.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "BPR is a **pairwise ranking-based** matrix factorization technique designed to optimize personalized recommendations for users based on **implicit feedback**. The core idea is to maximize the difference between the scores of items the user has interacted with and items the user has not interacted with, ensuring that the system learns to rank items based on preference.\n",
    "\n",
    "By leveraging implicit data, BPR provides a powerful framework for learning personalized recommendation systems that can be applied to various applications such as e-commerce, music, and movie recommendations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "import implicit\n",
    "from implicit.bpr import BayesianPersonalizedRanking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information about individual channels\n",
    "data_lake_prd_314410_cz_canais = pd.read_csv('../data/lookups/data-lake-prd-314410.cz.canais.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of hotel-channel combinations as of January 2025\n",
    "hotel_city_chanel_combin_extract  = pd.read_csv('../data/other/hotel_city_chanel_combin_extract.csv')\n",
    "hotel_city_chanel_combin_extract.dropna(inplace=True)\n",
    "hotel_city_chanel_combin_extract.drop(columns=['Cidade_ID'], inplace=True)\n",
    "hotel_city_chanel_combin_extract.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_city_chanel_combin_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique hotel and channel IDs\n",
    "hotel_ids = hotel_city_chanel_combin_extract[\"Hotel_ID\"].unique()\n",
    "channel_ids = hotel_city_chanel_combin_extract[\"Canal_ID\"].unique()\n",
    "\n",
    "# Create mappings\n",
    "hotel_to_idx = {hotel_id: idx for idx, hotel_id in enumerate(hotel_ids)}\n",
    "channel_to_idx = {channel_id: idx for idx, channel_id in enumerate(channel_ids)}\n",
    "\n",
    "# Apply mappings\n",
    "hotel_city_chanel_combin_extract[\"hotel_idx\"] = hotel_city_chanel_combin_extract[\"Hotel_ID\"].map(hotel_to_idx)\n",
    "hotel_city_chanel_combin_extract[\"channels_idx\"] = hotel_city_chanel_combin_extract[\"Canal_ID\"].map(channel_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sparse interaction matrix\n",
    "interaction_matrix = coo_matrix((\n",
    "    np.ones(len(hotel_city_chanel_combin_extract)),\n",
    "    (hotel_city_chanel_combin_extract[\"hotel_idx\"], hotel_city_chanel_combin_extract[\"channels_idx\"])\n",
    "))\n",
    "\n",
    "\n",
    "# Convert to CSR format for fast row access (required for BPR)\n",
    "interaction_matrix_csr = interaction_matrix.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_matrix_csr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the matrix to a \"positive feedback\" format expected by implicit\n",
    "\n",
    "interaction_matrix_csr = interaction_matrix_csr.astype(\"float32\")\n",
    "\n",
    "# Initialize the BPR model\n",
    "model = BayesianPersonalizedRanking(factors=50, iterations=5000, regularization=0.01, learning_rate=0.001)\n",
    "\n",
    "# Train the model on the interaction matrix\n",
    "model.fit(interaction_matrix_csr, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Get recommendations for a specific hotel (e.g., hotel ID 11334)\n",
    "\n",
    "hotel_id = 11334\n",
    "hotel_index = hotel_to_idx[hotel_id] # Convert to matrix index\n",
    "\n",
    "\n",
    "# Reshape the matrix to a single row\n",
    "user_interaction = interaction_matrix_csr[hotel_index]\n",
    "\n",
    "\n",
    "# Generate top 10 channel recommendations\n",
    "recommended_channel_indices, scores = model.recommend(hotel_index, user_interaction, N=50)\n",
    "recommended_channel_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert back to original Canal_ID values\n",
    "recommended_channels = [channel_ids[i] for i in recommended_channel_indices]\n",
    "\n",
    "# Print results\n",
    "print(f\"Top recommended channels for Hotel {hotel_id}: {recommended_channels}\")\n",
    "print(\"\")\n",
    "print(f\"Corresponding scores: {scores}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a dictionary to store top recommendations for each hotel\n",
    "top_recommendations = {}\n",
    "\n",
    "# Loop through all hotels to get recommendations\n",
    "for hotel_id in hotel_ids:\n",
    "    hotel_index = hotel_to_idx[hotel_id] # Convert to matrix index\n",
    "\n",
    "    # Reshape the matrix to a single row\n",
    "    user_interaction = interaction_matrix_csr[hotel_index]\n",
    "\n",
    "    # Generate top 50 channel recommendations\n",
    "    recommended_channel_indices, scores = model.recommend(hotel_index, user_interaction, N=50)\n",
    "    \n",
    "    # Convert back to original Canal_ID values\n",
    "    recommended_channels = [channel_ids[i] for i in recommended_channel_indices]\n",
    "\n",
    "    # Get the channels that the hotel has already interacted with\n",
    "    hotel_interacted_channels = hotel_city_chanel_combin_extract[hotel_city_chanel_combin_extract[\"Hotel_ID\"] == hotel_id][\"Canal_ID\"].values\n",
    "    \n",
    "     # Exclude channels the hotel already interacted with\n",
    "    filtered_recommended_channels = [\n",
    "        channel for channel in recommended_channels if channel not in hotel_interacted_channels\n",
    "    ]\n",
    "    \n",
    "\n",
    "    # Store the recommendations in the dictionary\n",
    "    top_recommendations[hotel_id] = {\n",
    "        'recommended_channels': filtered_recommended_channels,\n",
    "        'scores': scores[:len(filtered_recommended_channels)]  # Adjust scores to match the filtered list\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_id_example = 2\n",
    "if hotel_id_example in top_recommendations:\n",
    "    print(f\"Top recommended channels for Hotel {hotel_id_example}:\")\n",
    "    print(top_recommendations[hotel_id_example]['recommended_channels'])\n",
    "    print(\"\")\n",
    "    print(f\"Corresponding scores: {top_recommendations[hotel_id_example]['scores']}\")\n",
    "    print(\"\")\n",
    "    \n",
    "else:\n",
    "    print(f\"No recommendations found for Hotel {hotel_id_example}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_recommendations.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare a list to store the recommendation data\n",
    "recommendation_data = []\n",
    "\n",
    "# Loop through the top_recommendations dictionary and flatten the data into rows\n",
    "for hotel_id, recommendation in top_recommendations.items():\n",
    "    for channel, score in zip(recommendation['recommended_channels'], recommendation['scores']):\n",
    "        recommendation_data.append({\n",
    "            'Hotel_ID': hotel_id,\n",
    "            'Recommended_Channel': channel,\n",
    "            'Score': score\n",
    "        })\n",
    "\n",
    "# Create a DataFrame from the recommendation data\n",
    "recommendation_df = pd.DataFrame(recommendation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Export the DataFrame to a CSV file\n",
    "recommendation_df.to_csv('out/bpr_mf_hotel_channel_recommendations_top50.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "Bayesian Personalized Ranking (BPR) recommendations are often quite different from those obtained by Singular Value Decomposition (SVD), and this difference can be traced back to their underlying principles and how they handle the data.\n",
    "\n",
    "**1. Objective Function (Optimization Focus)**\n",
    "BPR (Bayesian Personalized Ranking) is designed to optimize pairwise ranking of items for each user. It works on implicit feedback and aims to rank items relative to each other. Specifically, BPR tries to maximize the probability that a user prefers an item they have interacted with over one they have not. Mathematically, BPR is based on the logistic loss function that tries to differentiate the scores for items the user has interacted with and those they have not. The goal is relative ranking between items, not absolute ratings.\n",
    "\n",
    "Focus: BPR cares about the ordering of items (which items are better than others) for each user.\n",
    "\n",
    "Data type: Implicit feedback (e.g., binary interactions: clicked vs. not clicked).\n",
    "\n",
    "SVD (Singular Value Decomposition), on the other hand, is a matrix factorization technique that minimizes the reconstruction error between the original matrix and the product of latent factor matrices. SVD is generally used with explicit feedback (e.g., ratings on a scale of 1-5). SVD seeks to find a low-rank approximation of the user-item matrix that minimizes the difference between the actual ratings and the predicted ratings.\n",
    "\n",
    "Focus: SVD tries to predict the absolute rating of an item for a user, not just the ranking of items.\n",
    "\n",
    "Data type: Explicit feedback (e.g., ratings).\n",
    "\n",
    "**2. Handling of Implicit vs. Explicit Feedback**\n",
    "BPR is specifically tailored for implicit feedback. It is built to work with binary interactions (e.g., did a user interact with an item or not), where there is no direct rating information. BPR models the probability of user preferences based on whether they interacted with an item and treats non-interacted items as implicitly disliked.\n",
    "\n",
    "SVD is generally used for explicit feedback data, where each entry in the matrix represents a rating (e.g., 1 to 5 stars). SVD tries to predict the rating for each user-item pair by decomposing the matrix into latent factors and minimizing the difference between actual ratings and predicted ratings.\n",
    "\n",
    "Since BPR ignores the actual ratings and only cares about the relative preferences between items, it often produces a different set of recommendations than SVD, especially when explicit ratings data is available.\n",
    "\n",
    "**3. Latent Factor Representation**\n",
    "In BPR, latent factors for both users and items are learned based on relative preference. When a user interacts with item i, the model will try to make the latent factors of i more preferred compared to items the user hasn't interacted with (i.e., item j).\n",
    "\n",
    "The latent factors learned by **BPR** are personalized in terms of preference ranking, and BPR doesn’t necessarily predict a specific \"rating\" or score for an item.\n",
    "\n",
    "**This typically results in recommendations that emphasize diverse or unexpected items** because BPR is less concerned with predicting exact ratings and more focused on ordering preferences.\n",
    "\n",
    "In contrast, **SVD** learns latent factors by trying to reconstruct the original matrix. SVD aims to minimize the difference between predicted ratings and observed ratings, which means that SVD's latent factors are more focused on rating prediction. The **items recommended by SVD tend to be those with the highest predicted ratings.**\n",
    "\n",
    "Since SVD tries to approximate user ratings, it typically leads to more conservative recommendations, suggesting items that are similar to those the user has rated highly in the past.\n",
    "\n",
    "**4. Recommendation Differences**\n",
    "BPR will recommend items that might be more unexpected or novel, as the system tries to find items the user is likely to prefer relative to other items they have not interacted with.\n",
    "\n",
    "SVD will likely recommend items that are similar to the ones the user has previously rated highly, as the model is focused on predicting the exact rating for each item and tends to suggest items that fit within the user’s known preferences.\n",
    "\n",
    "**5. Bias Toward Popularity (SVD)**\n",
    "**SVD may tend to recommend more popular items**, as those items tend to have the most data points and are therefore more easily predicted. If the user has rated items that are similar to popular ones, SVD will likely suggest those popular items.\n",
    "\n",
    "**BPR**, on the other hand, is not directly biased toward popularity, since it **cares more about individual user preferences and the ranking of items for each user**. As a result, BPR can sometimes recommend more niche or less popular items that the user may not have previously encountered.\n",
    "\n",
    "**Why the Difference in Recommendations?**\n",
    "\n",
    "BPR focuses on ranking items for a user based on previous interactions, which often leads to more exploratory recommendations (i.e., items the user might not have previously considered but would potentially like).\n",
    "SVD is focused on reconstructing ratings and may often suggest items that are similar to those the user has rated highly in the past. This can lead to more predictable or conservative recommendations.\n",
    "\n",
    "Exploration vs. Exploitation: In practice, systems that balance exploration (discovering new items via BPR) and exploitation (recommending top-rated items via SVD) are often more successful in providing a diverse yet relevant recommendation list.\n",
    "\n",
    "**Conclusion**\n",
    "\n",
    "The fundamental difference between BPR and SVD lies in their objective functions—BPR is focused on relative ranking based on implicit feedback, while SVD is focused on rating prediction based on explicit feedback. This results in BPR often suggesting novel and diverse items, while SVD tends to suggest popular and similar items based on a user’s past ratings. We suggest that, when in doubt, SVD suggestions should be prioritised. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bpr_mf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
