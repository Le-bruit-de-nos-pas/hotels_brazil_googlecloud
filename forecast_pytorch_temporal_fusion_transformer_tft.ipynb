{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1969, 0.6745, 0.1240],\n",
      "        [0.7551, 0.7888, 0.3326],\n",
      "        [0.4613, 0.8625, 0.8245],\n",
      "        [0.9027, 0.6587, 0.4636],\n",
      "        [0.4063, 0.6300, 0.6503]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Navigate one folder up\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# Where the files are located\n",
    "data = 'data\\pull-pesquisas-city-2851556'\n",
    "\n",
    "# Navigate down into the \"data\" folder\n",
    "data_dir = os.path.join(parent_dir, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: data-lake-prd-314410.cz.pull-pesquisas_city_2851556_2020.csv | Dimensions: (1, 22)\n",
      "File: data-lake-prd-314410.cz.pull-pesquisas_city_2851556_2021.csv | Dimensions: (115243, 22)\n",
      "File: data-lake-prd-314410.cz.pull-pesquisas_city_2851556_2022.csv | Dimensions: (1247986, 22)\n",
      "File: data-lake-prd-314410.cz.pull-pesquisas_city_2851556_2023.csv | Dimensions: (1430037, 22)\n",
      "File: data-lake-prd-314410.cz.pull-pesquisas_city_2851556_2024.csv | Dimensions: (1579543, 22)\n",
      "Combined DataFrame Dimensions: (4372810, 22)\n",
      "Row count verification successful! Total rows match.\n",
      "                      Data   Data_ID  Canal_ID  Credencial_ID  Integrador_ID  \\\n",
      "0  2020-06-05 00:00:00 UTC  20200605       367              0             50   \n",
      "1  2021-12-24 00:00:00 UTC  20211224         1              0              0   \n",
      "2  2021-12-24 00:00:00 UTC  20211224        10              0              0   \n",
      "3  2021-12-24 00:00:00 UTC  20211224       909           8112            120   \n",
      "4  2021-12-24 00:00:00 UTC  20211224       213           3697             55   \n",
      "\n",
      "   Cidade_ID  Hotel_ID  Ocupacao_ID  CheckIn_ID  CheckOut_ID  ...  Estadia  \\\n",
      "0    2851556      5406          100    20220913     20220914  ...        1   \n",
      "1    2851556      5706          200    20211224     20211225  ...        1   \n",
      "2    2851556      5731          200    20211224     20211225  ...        1   \n",
      "3    2851556      7154          200    20211224     20211226  ...        2   \n",
      "4    2851556      8973          200    20211224     20211225  ...        1   \n",
      "\n",
      "   Moeda_ID  TipoPesquisa_ID  Requests  Requests_Com_Warning  \\\n",
      "0        16                3         0                     0   \n",
      "1        16                3         0                     0   \n",
      "2        16                3         0                     0   \n",
      "3        16                3         0                     0   \n",
      "4        16                3         0                     0   \n",
      "\n",
      "   Requests_Sem_Response  Requests_Com_Disponibilidade  DiariaMedia  \\\n",
      "0                      0                             0     1510.425   \n",
      "1                      0                             0      285.520   \n",
      "2                      0                             0      227.000   \n",
      "3                      0                             0      172.460   \n",
      "4                      0                             0      158.550   \n",
      "\n",
      "                Timestamp_process  Reservas  \n",
      "0   2022-04-01 17:45:03.86921 UTC         1  \n",
      "1  2021-12-25 00:00:03.172167 UTC         1  \n",
      "2   2021-12-24 23:15:02.52311 UTC         1  \n",
      "3   2021-12-24 23:15:02.52311 UTC         1  \n",
      "4  2021-12-24 23:45:02.719486 UTC         1  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Variable to track total rows\n",
    "total_rows = 0\n",
    "\n",
    "# Loop through all files in the \"data\" folder\n",
    "try:\n",
    "    for file_name in os.listdir(data_dir):\n",
    "        \n",
    "        if file_name.endswith('.csv'):  # Check if the file is a CSV\n",
    "            \n",
    "            file_path = os.path.join(data_dir, file_name)\n",
    "            \n",
    "            # Read the CSV file into a DataFrame\n",
    "            df = pd.read_csv(file_path)\n",
    "            dataframes.append(df)  # Append the DataFrame to the list\n",
    "            \n",
    "             # Print dimensions of the current file\n",
    "            print(f\"File: {file_name} | Dimensions: {df.shape}\")\n",
    "            \n",
    "            # Add the number of rows to the total count\n",
    "            total_rows += df.shape[0]\n",
    "\n",
    "    # Concatenate all DataFrames in the list by binding rows\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    # Print dimensions of the combined DataFrame\n",
    "    print(f\"Combined DataFrame Dimensions: {combined_df.shape}\")\n",
    "\n",
    "    # Verify the sum of rows matches\n",
    "    if total_rows == combined_df.shape[0]:\n",
    "        print(\"Row count verification successful! Total rows match.\")\n",
    "    else:\n",
    "        print(\"Row count verification failed! Mismatch in row count.\")\n",
    "\n",
    "    print(combined_df.head())  # Display the first few rows of the combined DataFrame\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Folder '{data_dir}' not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['DiariaMedia'] = combined_df.apply(\n",
    "    lambda row: row['DiariaMedia'] * 0.16483969339817028 if row['Moeda_ID'] == 16 else row['DiariaMedia'], \n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df.loc[:, ['Data',  'Hotel_ID', 'Ocupacao_ID', 'DiariaMedia', \"Estadia\", 'Reservas']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df.loc[combined_df.index.repeat(combined_df['Reservas'])].reset_index(drop=True)\n",
    "combined_df.Reservas = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels_top_5 = combined_df.groupby('Hotel_ID').size().reset_index(name='Counts').sort_values(by='Counts', ascending=False).head(1)['Hotel_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102270, 6)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = combined_df[combined_df['Hotel_ID'].isin(hotels_top_5)]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[:, ['Data',  'Hotel_ID', 'DiariaMedia']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={'Data': 'date', 'Hotel_ID': 'hotel_id', 'DiariaMedia': 'price'}, inplace=True)\n",
    "data = data.loc[:, ['hotel_id',  'date', 'price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "#import holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert date to datetime\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "# Feature engineering\n",
    "data['day_of_week'] = data['date'].dt.dayofweek\n",
    "data['month'] = data['date'].dt.month\n",
    "data['year'] = data['date'].dt.year\n",
    "data['is_weekend'] = data['day_of_week'].isin([5, 6]).astype(int)\n",
    "\n",
    "# Add holiday feature\n",
    "#br_holidays = holidays.BR()\n",
    "#data['is_holiday'] = data['date'].isin(br_holidays).astype(int)\n",
    "\n",
    "# Lag features\n",
    "data = data.sort_values(by=['hotel_id', 'date'])\n",
    "for lag in [1, 7, 30]:\n",
    "    data[f'lag_{lag}'] = data.groupby('hotel_id')['price'].shift(lag)\n",
    "\n",
    "# Rolling statistics\n",
    "data['rolling_mean_7'] = data.groupby('hotel_id')['price'].rolling(window=7, min_periods=1).mean().reset_index(0, drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotel_id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_7</th>\n",
       "      <th>lag_30</th>\n",
       "      <th>rolling_mean_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>2094</td>\n",
       "      <td>2021-11-19 00:00:00+00:00</td>\n",
       "      <td>30.857991</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.857991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>2094</td>\n",
       "      <td>2021-11-19 00:00:00+00:00</td>\n",
       "      <td>32.709140</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "      <td>30.857991</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.783565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>2094</td>\n",
       "      <td>2021-11-19 00:00:00+00:00</td>\n",
       "      <td>28.840353</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "      <td>32.709140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.802495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>2094</td>\n",
       "      <td>2021-11-19 00:00:00+00:00</td>\n",
       "      <td>23.143493</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "      <td>28.840353</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.887744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>2094</td>\n",
       "      <td>2021-11-19 00:00:00+00:00</td>\n",
       "      <td>17.802687</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "      <td>23.143493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.670733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4847854</th>\n",
       "      <td>2094</td>\n",
       "      <td>2024-12-31 00:00:00+00:00</td>\n",
       "      <td>53.190472</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2024</td>\n",
       "      <td>0</td>\n",
       "      <td>23.595022</td>\n",
       "      <td>36.884530</td>\n",
       "      <td>42.198962</td>\n",
       "      <td>46.416484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4847858</th>\n",
       "      <td>2094</td>\n",
       "      <td>2024-12-31 00:00:00+00:00</td>\n",
       "      <td>51.017885</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2024</td>\n",
       "      <td>0</td>\n",
       "      <td>53.190472</td>\n",
       "      <td>61.686310</td>\n",
       "      <td>48.574961</td>\n",
       "      <td>44.892423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4847859</th>\n",
       "      <td>2094</td>\n",
       "      <td>2024-12-31 00:00:00+00:00</td>\n",
       "      <td>48.321981</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2024</td>\n",
       "      <td>0</td>\n",
       "      <td>51.017885</td>\n",
       "      <td>61.715981</td>\n",
       "      <td>30.825023</td>\n",
       "      <td>42.978995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4847860</th>\n",
       "      <td>2094</td>\n",
       "      <td>2024-12-31 00:00:00+00:00</td>\n",
       "      <td>29.176626</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2024</td>\n",
       "      <td>0</td>\n",
       "      <td>48.321981</td>\n",
       "      <td>48.574961</td>\n",
       "      <td>30.825023</td>\n",
       "      <td>40.207804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4847863</th>\n",
       "      <td>2094</td>\n",
       "      <td>2024-12-31 00:00:00+00:00</td>\n",
       "      <td>31.990439</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2024</td>\n",
       "      <td>0</td>\n",
       "      <td>29.176626</td>\n",
       "      <td>43.694058</td>\n",
       "      <td>35.623852</td>\n",
       "      <td>38.535859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102270 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         hotel_id                      date      price  day_of_week  month  \\\n",
       "1096         2094 2021-11-19 00:00:00+00:00  30.857991            4     11   \n",
       "1224         2094 2021-11-19 00:00:00+00:00  32.709140            4     11   \n",
       "1240         2094 2021-11-19 00:00:00+00:00  28.840353            4     11   \n",
       "1279         2094 2021-11-19 00:00:00+00:00  23.143493            4     11   \n",
       "1303         2094 2021-11-19 00:00:00+00:00  17.802687            4     11   \n",
       "...           ...                       ...        ...          ...    ...   \n",
       "4847854      2094 2024-12-31 00:00:00+00:00  53.190472            1     12   \n",
       "4847858      2094 2024-12-31 00:00:00+00:00  51.017885            1     12   \n",
       "4847859      2094 2024-12-31 00:00:00+00:00  48.321981            1     12   \n",
       "4847860      2094 2024-12-31 00:00:00+00:00  29.176626            1     12   \n",
       "4847863      2094 2024-12-31 00:00:00+00:00  31.990439            1     12   \n",
       "\n",
       "         year  is_weekend      lag_1      lag_7     lag_30  rolling_mean_7  \n",
       "1096     2021           0        NaN        NaN        NaN       30.857991  \n",
       "1224     2021           0  30.857991        NaN        NaN       31.783565  \n",
       "1240     2021           0  32.709140        NaN        NaN       30.802495  \n",
       "1279     2021           0  28.840353        NaN        NaN       28.887744  \n",
       "1303     2021           0  23.143493        NaN        NaN       26.670733  \n",
       "...       ...         ...        ...        ...        ...             ...  \n",
       "4847854  2024           0  23.595022  36.884530  42.198962       46.416484  \n",
       "4847858  2024           0  53.190472  61.686310  48.574961       44.892423  \n",
       "4847859  2024           0  51.017885  61.715981  30.825023       42.978995  \n",
       "4847860  2024           0  48.321981  48.574961  30.825023       40.207804  \n",
       "4847863  2024           0  29.176626  43.694058  35.623852       38.535859  \n",
       "\n",
       "[102270 rows x 11 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'date' is a pandas datetime type\n",
    "data[\"date\"] = pd.to_datetime(data[\"date\"])\n",
    "\n",
    "# Create a sequential time index\n",
    "data = data.sort_values([\"hotel_id\", \"date\"])  # Sort by group and time\n",
    "data[\"time_idx\"] = data.groupby(\"hotel_id\").cumcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\paulo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "c:\\Users\\paulo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
      "c:\\Users\\paulo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_forecasting\\models\\temporal_fusion_transformer\\__init__.py:171: UserWarning: In pytorch-forecasting models, on versions 1.1.X, the default optimizer defaults to 'adam', if pytorch_optimizer is not installed, otherwise it defaults to 'ranger' from pytorch_optimizer. From version 1.2.0, the default optimizer will be 'adam' regardless of whether pytorch_optimizer is installed, in order to minimize the number of dependencies in default parameter settings. Users who wish to ensure their code continues using 'ranger' as optimizer should ensure that pytorch_optimizer is installed, and set the optimizer parameter explicitly to 'ranger'.\n",
      "  super().__init__(loss=loss, logging_metrics=logging_metrics, **kwargs)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "`model` must be a `LightningModule` or `torch._dynamo.OptimizedModule`, got `TemporalFusionTransformer`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [50]\u001b[0m, in \u001b[0;36m<cell line: 65>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m     64\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)  \u001b[38;5;66;03m# Adjust GPU usage\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Forecast\u001b[39;00m\n\u001b[0;32m     68\u001b[0m predictions \u001b[38;5;241m=\u001b[39m tft\u001b[38;5;241m.\u001b[39mpredict(val_dataloader)\n",
      "File \u001b[1;32mc:\\Users\\paulo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:533\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    501\u001b[0m     model: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.LightningModule\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    505\u001b[0m     ckpt_path: Optional[_PATH] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    506\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    507\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Runs the full optimization routine.\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \n\u001b[0;32m    509\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    531\u001b[0m \n\u001b[0;32m    532\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 533\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_unwrap_optimized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    534\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m_lightning_module \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m    535\u001b[0m     _verify_strategy_supports_compile(model, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy)\n",
      "File \u001b[1;32mc:\\Users\\paulo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\utilities\\compile.py:111\u001b[0m, in \u001b[0;36m_maybe_unwrap_optimized\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[0;32m    110\u001b[0m _check_mixed_imports(model)\n\u001b[1;32m--> 111\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`model` must be a `LightningModule` or `torch._dynamo.OptimizedModule`, got `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(model)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    113\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: `model` must be a `LightningModule` or `torch._dynamo.OptimizedModule`, got `TemporalFusionTransformer`"
     ]
    }
   ],
   "source": [
    "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_lightning import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# Ensure 'time_idx' exists\n",
    "data = data.sort_values([\"hotel_id\", \"date\"])  # Sort by group and time\n",
    "data[\"time_idx\"] = data.groupby(\"hotel_id\").cumcount()\n",
    "\n",
    "# Add date-based features\n",
    "data[\"day_of_week\"] = data[\"date\"].dt.dayofweek\n",
    "data[\"month\"] = data[\"date\"].dt.month\n",
    "data[\"year\"] = data[\"date\"].dt.year\n",
    "data[\"is_weekend\"] = (data[\"day_of_week\"] >= 5).astype(int)\n",
    "\n",
    "# Split data into train and validation indices using sklearn's train_test_split\n",
    "train_indices, val_indices = train_test_split(data.index, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Create the TimeSeriesDataSet for train and validation based on the split indices\n",
    "train_data = data.loc[train_indices]\n",
    "val_data = data.loc[val_indices]\n",
    "\n",
    "# Define the TimeSeriesDataSet\n",
    "max_encoder_length = 90  # Lookback window\n",
    "max_prediction_length = 30  # Forecast window\n",
    "\n",
    "train_dataset = TimeSeriesDataSet(\n",
    "    train_data,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"price\",\n",
    "    group_ids=[\"hotel_id\"],\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    time_varying_known_reals=[\"day_of_week\", \"month\", \"year\", \"is_weekend\"],\n",
    "    time_varying_unknown_reals=[\"price\"],\n",
    "    target_normalizer=GroupNormalizer(groups=[\"hotel_id\"]),\n",
    ")\n",
    "\n",
    "val_dataset = TimeSeriesDataSet(\n",
    "    val_data,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"price\",\n",
    "    group_ids=[\"hotel_id\"],\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    time_varying_known_reals=[\"day_of_week\", \"month\", \"year\", \"is_weekend\"],\n",
    "    time_varying_unknown_reals=[\"price\"],\n",
    "    target_normalizer=GroupNormalizer(groups=[\"hotel_id\"]),\n",
    ")\n",
    "\n",
    "# Create DataLoaders for train and validation\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Model definition\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    train_dataset, learning_rate=0.03, hidden_size=16, attention_head_size=1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "trainer = Trainer(max_epochs=10)  # Adjust GPU usage\n",
    "trainer.fit(tft, train_dataloader, val_dataloader)\n",
    "\n",
    "# Forecast\n",
    "predictions = tft.predict(val_dataloader)\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
