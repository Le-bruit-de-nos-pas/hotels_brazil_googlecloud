{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import os\n",
    "import gc\n",
    "import psutil\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from scipy.signal import savgol_filter\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Navigate one folder up\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# Where the files are located\n",
    "data = 'data\\pull-pesquisas-city-2851556'\n",
    "\n",
    "# Navigate down into the \"data\" folder\n",
    "data_dir = os.path.join(parent_dir, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Variable to track total rows\n",
    "total_rows = 0\n",
    "\n",
    "# Loop through all files in the \"data\" folder\n",
    "try:\n",
    "    for file_name in os.listdir(data_dir):\n",
    "        \n",
    "        if file_name.endswith('.csv'):  # Check if the file is a CSV\n",
    "            \n",
    "            file_path = os.path.join(data_dir, file_name)\n",
    "            \n",
    "            # Read the CSV file into a DataFrame\n",
    "            df = pd.read_csv(file_path)\n",
    "            dataframes.append(df)  # Append the DataFrame to the list\n",
    "            \n",
    "             # Print dimensions of the current file\n",
    "            print(f\"File: {file_name} | Dimensions: {df.shape}\")\n",
    "            \n",
    "            # Add the number of rows to the total count\n",
    "            total_rows += df.shape[0]\n",
    "\n",
    "    # Concatenate all DataFrames in the list by binding rows\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    # Print dimensions of the combined DataFrame\n",
    "    print(f\"Combined DataFrame Dimensions: {combined_df.shape}\")\n",
    "\n",
    "    # Verify the sum of rows matches\n",
    "    if total_rows == combined_df.shape[0]:\n",
    "        print(\"Row count verification successful! Total rows match.\")\n",
    "    else:\n",
    "        print(\"Row count verification failed! Mismatch in row count.\")\n",
    "\n",
    "    print(combined_df.head())  # Display the first few rows of the combined DataFrame\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Folder '{data_dir}' not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the variables to delete manually\n",
    "variables_to_delete = ['current_dir', 'parent_dir', 'data_dir', 'dataframes', 'file_name', 'file_path', 'df', 'total_rows', 'data', 'var', 'variables_to_delete']\n",
    "\n",
    "# Iterate through the list and delete each variable\n",
    "for var in variables_to_delete:\n",
    "    if var in globals():  # Ensure the variable exists before trying to delete\n",
    "        del globals()[var]\n",
    "\n",
    "print(\"Memory cleared. Retained variables: combined_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get memory usage in bytes\n",
    "def memory_usage():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return process.memory_info().rss  # Resident Set Size (in bytes)\n",
    "\n",
    "# Check memory usage before garbage collection\n",
    "memory_before = memory_usage()\n",
    "\n",
    "# Trigger garbage collection\n",
    "gc.collect()\n",
    "\n",
    "# Check memory usage after garbage collection\n",
    "memory_after = memory_usage()\n",
    "\n",
    "# Calculate memory cleared\n",
    "memory_cleared = memory_before - memory_after\n",
    "\n",
    "print(f\"Memory before GC: {memory_before / 1024**2:.2f} MB\")\n",
    "print(f\"Memory after GC: {memory_after / 1024**2:.2f} MB\")\n",
    "print(f\"Memory cleared: {memory_cleared / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_id_min = combined_df['Data_ID'].min()\n",
    "data_id_max = combined_df['Data_ID'].max()\n",
    "print(f\"Min Data_ID: {data_id_min}, Max Data_ID: {data_id_max}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_hotel_ids = combined_df['Hotel_ID'].nunique()\n",
    "print(f\"Number of distinct Hotel_IDs: {distinct_hotel_ids}\")\n",
    "del distinct_hotel_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check memory usage before garbage collection\n",
    "memory_before = memory_usage()\n",
    "\n",
    "# Trigger garbage collection\n",
    "gc.collect()\n",
    "\n",
    "# Check memory usage after garbage collection\n",
    "memory_after = memory_usage()\n",
    "\n",
    "# Calculate memory cleared\n",
    "memory_cleared = memory_before - memory_after\n",
    "\n",
    "print(f\"Memory before GC: {memory_before / 1024**2:.2f} MB\")\n",
    "print(f\"Memory after GC: {memory_after / 1024**2:.2f} MB\")\n",
    "print(f\"Memory cleared: {memory_cleared / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of distinct Hotel_IDs: {combined_df['Hotel_ID'].nunique()}\")\n",
    "print(f\"Number of distinct Moeda_IDs: {combined_df['Moeda_ID'].nunique()}\")\n",
    "print(f\"Number of distinct Canal_IDs: {combined_df['Canal_ID'].nunique()}\")\n",
    "print(f\"Number of distinct Reservas: {combined_df['Reservas'].nunique()}\")\n",
    "print(f\"Number of distinct DiariaMedia: {combined_df['DiariaMedia'].nunique()}\")\n",
    "print(f\"Number of distinct Estadias: {combined_df['Estadia'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['Moeda_ID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['DiariaMedia'] = combined_df.apply(\n",
    "    lambda row: row['DiariaMedia'] * 0.16483969339817028 if row['Moeda_ID'] == 16 else row['DiariaMedia'], \n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "selected_columns_df = combined_df.loc[:, ['Data', 'Data_ID', 'Moeda_ID', 'Hotel_ID', 'Ocupacao_ID', 'DiariaMedia', \"Estadia\", 'Reservas']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of distinct Reservas: {selected_columns_df['Reservas'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(selected_columns_df['Data_ID'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns_df.DiariaMedia.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers at some point, but to be discussed\n",
    "# selected_columns_df[selected_columns_df['DiariaMedia'] <= 1000] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns_df = selected_columns_df.loc[:, ['Data', 'Data_ID',  'Hotel_ID', 'Ocupacao_ID', 'DiariaMedia', \"Estadia\", 'Reservas']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns_df.Reservas.sum() # 4925449"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_df = selected_columns_df.loc[selected_columns_df.index.repeat(selected_columns_df['Reservas'])].reset_index(drop=True)\n",
    "expanded_df.Reservas = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_df.Reservas.sum() # 4925449 OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_df.groupby('Hotel_ID').size().reset_index(name='Counts').sort_values(by='Counts', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lake_prd_314410_cz_hoteis_competidores = pd.read_csv('c:\\\\Users\\\\paulo\\\\Desktop\\\\hotels brazil\\\\data\\\\lookups\\\\data-lake-prd-314410.cz.hoteis-competidores.csv')\n",
    "data_lake_prd_314410_cz_hoteis_competidores[data_lake_prd_314410_cz_hoteis_competidores['Hotel_ID'] == 2094]['Competidor_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_df = expanded_df[expanded_df['DiariaMedia'] <= 1000]\n",
    "hotel_df = hotel_df[hotel_df['Hotel_ID'].isin([2814, 3096, 3691, 2094])] \n",
    "hotel_df = hotel_df.dropna(subset=['DiariaMedia', 'Data'])\n",
    "# Convert 'Data' to datetime format (if not already in datetime)\n",
    "hotel_df['Data'] = pd.to_datetime(hotel_df['Data'])\n",
    "\n",
    "# Sort the DataFrame by 'Data' to make sure the dates are in order for the fitting\n",
    "hotel_df = hotel_df.sort_values(by='Data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_df.groupby('Hotel_ID').size().reset_index(name='Counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom colors for each hotel\n",
    "colors = ['red', 'blue','orange', 'purple']\n",
    "\n",
    "# Create an empty figure to hold the multiple fitted curves\n",
    "fig = px.line(title='LOESS Smoothed Fits of DiariaMedia Over Time for Selected Hotels')\n",
    "\n",
    "# Loop through each hotel and create a smoothed fit for each one\n",
    "for i, hotel_id in enumerate([2094,  2814, 3096, 3691]):\n",
    "    # Filter data for the current hotel\n",
    "    hotel_data = hotel_df[hotel_df['Hotel_ID'] == hotel_id]\n",
    "\n",
    "     # Filter the data to only include dates from January 2022 onwards\n",
    "    hotel_data['Data'] = hotel_data['Data'].dt.tz_localize(None)  # Remove timezone\n",
    "    hotel_data = hotel_data[hotel_data['Data'] >= pd.to_datetime('2022-01-01')]\n",
    "\n",
    "    # Get the values for fitting\n",
    "    x_values = hotel_data['Data'].astype(np.int64) / 10**9  # Convert datetime to UNIX timestamp (seconds)\n",
    "    y_values = hotel_data['DiariaMedia']\n",
    "\n",
    "    # Apply LOESS smoothing (use frac for the smoothing parameter)\n",
    "    smoothed_data = lowess(y_values, x_values, frac=0.1)  # Adjust frac for the level of smoothing (between 0 and 1)\n",
    "\n",
    "    # Add the smoothed fit to the plot for the current hotel\n",
    "    fig.add_scatter(x=hotel_data['Data'], y=smoothed_data[:, 1], mode='lines', name=f'Hotel_ID {hotel_id}', \n",
    "                    line=dict(color=colors[i], dash='dash'))\n",
    "\n",
    "# Customize the layout for better appearance\n",
    "fig.update_layout(\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='DiariaMedia (USD)',\n",
    "    template='plotly_dark',  # Optional: choose a theme\n",
    "    xaxis=dict(showgrid=True, tickangle=45),  # Rotate x-axis labels for better readability\n",
    "    yaxis=dict(showgrid=True),\n",
    ")\n",
    "\n",
    "# Show the interactive plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
