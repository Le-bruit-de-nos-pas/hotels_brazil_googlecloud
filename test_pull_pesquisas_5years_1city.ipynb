{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "import psutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Navigate one folder up\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# Where the files are located\n",
    "data = 'data\\pull-pesquisas-city-2851556'\n",
    "\n",
    "# Navigate down into the \"data\" folder\n",
    "data_dir = os.path.join(parent_dir, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: data-lake-prd-314410.cz.pull-pesquisas_city_2851556_2020.csv | Dimensions: (1, 22)\n",
      "File: data-lake-prd-314410.cz.pull-pesquisas_city_2851556_2021.csv | Dimensions: (115243, 22)\n",
      "File: data-lake-prd-314410.cz.pull-pesquisas_city_2851556_2022.csv | Dimensions: (1247986, 22)\n",
      "File: data-lake-prd-314410.cz.pull-pesquisas_city_2851556_2023.csv | Dimensions: (1430037, 22)\n",
      "File: data-lake-prd-314410.cz.pull-pesquisas_city_2851556_2024.csv | Dimensions: (1579543, 22)\n",
      "Combined DataFrame Dimensions: (4372810, 22)\n",
      "Row count verification successful! Total rows match.\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Variable to track total rows\n",
    "total_rows = 0\n",
    "\n",
    "# Loop through all files in the \"data\" folder\n",
    "try:\n",
    "    for file_name in os.listdir(data_dir):\n",
    "        \n",
    "        if file_name.endswith('.csv'):  # Check if the file is a CSV\n",
    "            \n",
    "            file_path = os.path.join(data_dir, file_name)\n",
    "            \n",
    "            # Read the CSV file into a DataFrame\n",
    "            df = pd.read_csv(file_path)\n",
    "            dataframes.append(df)  # Append the DataFrame to the list\n",
    "            \n",
    "             # Print dimensions of the current file\n",
    "            print(f\"File: {file_name} | Dimensions: {df.shape}\")\n",
    "            \n",
    "            # Add the number of rows to the total count\n",
    "            total_rows += df.shape[0]\n",
    "\n",
    "    # Concatenate all DataFrames in the list by binding rows\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    # Print dimensions of the combined DataFrame\n",
    "    print(f\"Combined DataFrame Dimensions: {combined_df.shape}\")\n",
    "\n",
    "    # Verify the sum of rows matches\n",
    "    if total_rows == combined_df.shape[0]:\n",
    "        print(\"Row count verification successful! Total rows match.\")\n",
    "    else:\n",
    "        print(\"Row count verification failed! Mismatch in row count.\")\n",
    "\n",
    "    print(combined_df.head())  # Display the first few rows of the combined DataFrame\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Folder '{data_dir}' not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4372810, 22)\n"
     ]
    }
   ],
   "source": [
    "print(combined_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory cleared. Retained variables: combined_df\n"
     ]
    }
   ],
   "source": [
    "# List the variables to delete manually\n",
    "variables_to_delete = ['current_dir', 'parent_dir', 'data_dir', 'dataframes', 'file_name', 'file_path', 'df', 'total_rows', 'data', 'var', 'variables_to_delete']\n",
    "\n",
    "# Iterate through the list and delete each variable\n",
    "for var in variables_to_delete:\n",
    "    if var in globals():  # Ensure the variable exists before trying to delete\n",
    "        del globals()[var]\n",
    "\n",
    "print(\"Memory cleared. Retained variables: combined_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory before GC: 907.34 MB\n",
      "Memory after GC: 907.34 MB\n",
      "Memory cleared: 0.00 MB\n"
     ]
    }
   ],
   "source": [
    "# Function to get memory usage in bytes\n",
    "def memory_usage():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return process.memory_info().rss  # Resident Set Size (in bytes)\n",
    "\n",
    "# Check memory usage before garbage collection\n",
    "memory_before = memory_usage()\n",
    "\n",
    "# Trigger garbage collection\n",
    "gc.collect()\n",
    "\n",
    "# Check memory usage after garbage collection\n",
    "memory_after = memory_usage()\n",
    "\n",
    "# Calculate memory cleared\n",
    "memory_cleared = memory_before - memory_after\n",
    "\n",
    "print(f\"Memory before GC: {memory_before / 1024**2:.2f} MB\")\n",
    "print(f\"Memory after GC: {memory_after / 1024**2:.2f} MB\")\n",
    "print(f\"Memory cleared: {memory_cleared / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Data_ID: 20200605, Max Data_ID: 20241231\n"
     ]
    }
   ],
   "source": [
    "data_id_min = combined_df['Data_ID'].min()\n",
    "data_id_max = combined_df['Data_ID'].max()\n",
    "print(f\"Min Data_ID: {data_id_min}, Max Data_ID: {data_id_max}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct Hotel_IDs: 414\n"
     ]
    }
   ],
   "source": [
    "distinct_hotel_ids = combined_df['Hotel_ID'].nunique()\n",
    "print(f\"Number of distinct Hotel_IDs: {distinct_hotel_ids}\")\n",
    "del distinct_hotel_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory before GC: 909.36 MB\n",
      "Memory after GC: 909.36 MB\n",
      "Memory cleared: 0.00 MB\n"
     ]
    }
   ],
   "source": [
    "# Check memory usage before garbage collection\n",
    "memory_before = memory_usage()\n",
    "\n",
    "# Trigger garbage collection\n",
    "gc.collect()\n",
    "\n",
    "# Check memory usage after garbage collection\n",
    "memory_after = memory_usage()\n",
    "\n",
    "# Calculate memory cleared\n",
    "memory_cleared = memory_before - memory_after\n",
    "\n",
    "print(f\"Memory before GC: {memory_before / 1024**2:.2f} MB\")\n",
    "print(f\"Memory after GC: {memory_after / 1024**2:.2f} MB\")\n",
    "print(f\"Memory cleared: {memory_cleared / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct Hotel_IDs: 414\n",
      "Number of distinct Moeda_IDs: 2\n",
      "Number of distinct Canal_IDs: 366\n",
      "Number of distinct Reservas: 56\n",
      "Number of distinct DiariaMedia: 472813\n",
      "Number of distinct Estadias: 89\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of distinct Hotel_IDs: {combined_df['Hotel_ID'].nunique()}\")\n",
    "print(f\"Number of distinct Moeda_IDs: {combined_df['Moeda_ID'].nunique()}\")\n",
    "print(f\"Number of distinct Canal_IDs: {combined_df['Canal_ID'].nunique()}\")\n",
    "print(f\"Number of distinct Reservas: {combined_df['Reservas'].nunique()}\")\n",
    "print(f\"Number of distinct DiariaMedia: {combined_df['DiariaMedia'].nunique()}\")\n",
    "print(f\"Number of distinct Estadias: {combined_df['Estadia'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 16, 109], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df['Moeda_ID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['DiariaMedia'] = combined_df.apply(\n",
    "    lambda row: row['DiariaMedia'] * 0.16483969339817028 if row['Moeda_ID'] == 16 else row['DiariaMedia'], \n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "selected_columns_df = combined_df.loc[:, ['Data', 'Data_ID', 'Hotel_ID', 'Ocupacao_ID', 'DiariaMedia', \"Estadia\", 'Reservas']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct Reservas: 56\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of distinct Reservas: {selected_columns_df['Reservas'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
