{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import os\n",
    "from prophet import Prophet\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Navigate one folder up\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# Where the files are located\n",
    "data = \"out/\"\n",
    "\n",
    "# Navigate down into the \"data\" folder\n",
    "data_dir = os.path.join(parent_dir, data)\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Variable to track total rows\n",
    "total_rows = 0\n",
    "\n",
    "# Loop through all files in the \"data\" folder\n",
    "try:\n",
    "    for file_name in os.listdir(data_dir):\n",
    "        \n",
    "        if file_name.endswith('.csv'):  # Check if the file is a CSV\n",
    "            \n",
    "            file_path = os.path.join(data_dir, file_name)\n",
    "            \n",
    "            # Read the CSV file into a DataFrame\n",
    "            df = pd.read_csv(file_path)\n",
    "            dataframes.append(df)  # Append the DataFrame to the list\n",
    "            \n",
    "             # Print dimensions of the current file\n",
    "            print(f\"File: {file_name} | Dimensions: {df.shape}\")\n",
    "            \n",
    "            # Add the number of rows to the total count\n",
    "            total_rows += df.shape[0]\n",
    "\n",
    "    # Concatenate all DataFrames in the list by binding rows\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    # Print dimensions of the combined DataFrame\n",
    "    print(f\"Combined DataFrame Dimensions: {combined_df.shape}\")\n",
    "\n",
    "    # Verify the sum of rows matches\n",
    "    if total_rows == combined_df.shape[0]:\n",
    "        print(\"Row count verification successful! Total rows match.\")\n",
    "    else:\n",
    "        print(\"Row count verification failed! Mismatch in row count.\")\n",
    "\n",
    "    print(combined_df.head())  # Display the first few rows of the combined DataFrame\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Folder '{data_dir}' not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "combined_df.to_csv(\"../out/all_hotel_forecasts_04_02_2025.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hotel_forecasts_04_02_2025 = combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Navigate one folder up\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# Where the files are located\n",
    "data = \"data/other/2021_Jan2025_PricesHotelsDates\"\n",
    "\n",
    "# Navigate down into the \"data\" folder\n",
    "data_dir = os.path.join(parent_dir, data)\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Variable to track total rows\n",
    "total_rows = 0\n",
    "\n",
    "# Loop through all files in the \"data\" folder\n",
    "try:\n",
    "    for file_name in os.listdir(data_dir):\n",
    "        \n",
    "        if file_name.endswith('.csv'):  # Check if the file is a CSV\n",
    "            \n",
    "            file_path = os.path.join(data_dir, file_name)\n",
    "            \n",
    "            # Read the CSV file into a DataFrame\n",
    "            df = pd.read_csv(file_path)\n",
    "            dataframes.append(df)  # Append the DataFrame to the list\n",
    "            \n",
    "             # Print dimensions of the current file\n",
    "            print(f\"File: {file_name} | Dimensions: {df.shape}\")\n",
    "            \n",
    "            # Add the number of rows to the total count\n",
    "            total_rows += df.shape[0]\n",
    "\n",
    "    # Concatenate all DataFrames in the list by binding rows\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    # Print dimensions of the combined DataFrame\n",
    "    print(f\"Combined DataFrame Dimensions: {combined_df.shape}\")\n",
    "\n",
    "    # Verify the sum of rows matches\n",
    "    if total_rows == combined_df.shape[0]:\n",
    "        print(\"Row count verification successful! Total rows match.\")\n",
    "    else:\n",
    "        print(\"Row count verification failed! Mismatch in row count.\")\n",
    "\n",
    "    print(combined_df.head())  # Display the first few rows of the combined DataFrame\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Folder '{data_dir}' not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['Data'] = pd.to_datetime(combined_df['Data']).dt.tz_localize(None)\n",
    "combined_df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filter for data in 2024\n",
    "hotels_2024 = combined_df[combined_df['Data'].dt.year == 2024]['Hotel_ID'].unique()\n",
    "\n",
    "# Filter the original combined_df to keep only hotels that appeared in 2024\n",
    "combined_df = combined_df[combined_df['Hotel_ID'].isin(hotels_2024)]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df.loc[:, ['Data',  'Hotel_ID', 'DiariaMedia']]\n",
    "\n",
    "combined_df.rename(columns={'Data': 'ds', 'Hotel_ID': 'hotel_id', 'DiariaMedia': 'y'}, inplace=True)\n",
    "\n",
    "combined_df = combined_df.loc[:, ['hotel_id',  'ds', 'y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df.groupby(['hotel_id', 'ds']).agg({'y': 'mean'}).reset_index()\n",
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'hotel_id' and count the number of rows for each hotel\n",
    "hotel_counts = combined_df.groupby('hotel_id').size()\n",
    "\n",
    "# Filter for hotels that have more than 92 rows\n",
    "hotels_with_more_than_30_rows = hotel_counts[hotel_counts > 30].index\n",
    "\n",
    "# Filter the original table for these hotels\n",
    "filtered_combined_df = combined_df[combined_df['hotel_id'].isin(hotels_with_more_than_30_rows)]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "filtered_combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hotel_forecasts_04_02_2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_list = all_hotel_forecasts_04_02_2025['hotel'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_combined_df.rename(columns={'hotel_id': 'hotel'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hotel_forecasts_04_02_2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_combined_df[\"ds\"] = pd.to_datetime(filtered_combined_df[\"ds\"])\n",
    "all_hotel_forecasts_04_02_2025[\"ds\"] = pd.to_datetime(all_hotel_forecasts_04_02_2025[\"ds\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize a list to store results\n",
    "error_metrics = []\n",
    "\n",
    "# Loop through each hotel\n",
    "for hotel in hotel_list:\n",
    "    # Get actual and predicted values for the historical period\n",
    "    hotel_forecast = all_hotel_forecasts_04_02_2025[all_hotel_forecasts_04_02_2025[\"hotel\"] == hotel]\n",
    "    historical_data = filtered_combined_df[filtered_combined_df[\"hotel\"] == hotel]\n",
    "\n",
    "    # Merge on the date column to align actual and predicted values\n",
    "    comparison = historical_data.merge(hotel_forecast, on=\"ds\", how=\"inner\")\n",
    "\n",
    "    # Compute error metrics\n",
    "    mae = mean_absolute_error(comparison[\"y\"], comparison[\"yhat\"])\n",
    "    rmse = np.sqrt(mean_squared_error(comparison[\"y\"], comparison[\"yhat\"]))\n",
    "    mape = np.mean(np.abs((comparison[\"y\"] - comparison[\"yhat\"]) / comparison[\"y\"])) * 100\n",
    "\n",
    "    # Append results to the list\n",
    "    error_metrics.append({\"hotel\": hotel, \"MAE\": mae, \"RMSE\": rmse, \"MAPE\": mape})\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "error_df = pd.DataFrame(error_metrics)\n",
    "\n",
    "# Display the error metrics table\n",
    "print(error_df)\n",
    "\n",
    "# Save to CSV for further analysis\n",
    "error_df.to_csv(\"../out/hotel_error_metrics.csv\", index=False)\n",
    "\n",
    "print(\"Error metrics saved to 'hotel_error_metrics.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df['MAPE'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where MAPE is infinite\n",
    "error_df = error_df.replace([np.inf, -np.inf], np.nan).dropna(subset=[\"MAPE\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df['MAPE'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a histogram of the \"MAPE\" variable\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(data=error_df[ (error_df['MAPE']<100) & (error_df['MAPE']>0) ], x=\"MAPE\", bins=500, kde=False)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"MAPE\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of MAPE\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
