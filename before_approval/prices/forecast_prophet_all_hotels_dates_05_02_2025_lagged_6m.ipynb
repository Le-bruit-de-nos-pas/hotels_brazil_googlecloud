{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import os\n",
    "from prophet import Prophet\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Navigate one folder up\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# Where the files are located\n",
    "data = \"data/other/2021_Jan2025_PricesHotelsDates\"\n",
    "\n",
    "# Navigate down into the \"data\" folder\n",
    "data_dir = os.path.join(parent_dir, data)\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Variable to track total rows\n",
    "total_rows = 0\n",
    "\n",
    "# Loop through all files in the \"data\" folder\n",
    "try:\n",
    "    for file_name in os.listdir(data_dir):\n",
    "        \n",
    "        if file_name.endswith('.csv'):  # Check if the file is a CSV\n",
    "            \n",
    "            file_path = os.path.join(data_dir, file_name)\n",
    "            \n",
    "            # Read the CSV file into a DataFrame\n",
    "            df = pd.read_csv(file_path)\n",
    "            dataframes.append(df)  # Append the DataFrame to the list\n",
    "            \n",
    "             # Print dimensions of the current file\n",
    "            print(f\"File: {file_name} | Dimensions: {df.shape}\")\n",
    "            \n",
    "            # Add the number of rows to the total count\n",
    "            total_rows += df.shape[0]\n",
    "\n",
    "    # Concatenate all DataFrames in the list by binding rows\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    # Print dimensions of the combined DataFrame\n",
    "    print(f\"Combined DataFrame Dimensions: {combined_df.shape}\")\n",
    "\n",
    "    # Verify the sum of rows matches\n",
    "    if total_rows == combined_df.shape[0]:\n",
    "        print(\"Row count verification successful! Total rows match.\")\n",
    "    else:\n",
    "        print(\"Row count verification failed! Mismatch in row count.\")\n",
    "\n",
    "    print(combined_df.head())  # Display the first few rows of the combined DataFrame\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Folder '{data_dir}' not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del current_dir, data, data_dir, dataframes, df, file_name, file_path, parent_dir, total_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['Data'] = pd.to_datetime(combined_df['Data']).dt.tz_localize(None)\n",
    "combined_df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filter for data in 2024\n",
    "hotels_2024 = combined_df[combined_df['Data'].dt.year == 2024]['Hotel_ID'].unique()\n",
    "\n",
    "# Filter the original combined_df to keep only hotels that appeared in 2024\n",
    "combined_df = combined_df[combined_df['Hotel_ID'].isin(hotels_2024)]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels_2024.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df.loc[:, ['Data',  'Hotel_ID', 'DiariaMedia']]\n",
    "\n",
    "combined_df.rename(columns={'Data': 'ds', 'Hotel_ID': 'hotel_id', 'DiariaMedia': 'y'}, inplace=True)\n",
    "\n",
    "combined_df = combined_df.loc[:, ['hotel_id',  'ds', 'y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df.groupby(['hotel_id', 'ds']).agg({'y': 'mean'}).reset_index()\n",
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_df['ds'].min())\n",
    "print(combined_df['ds'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df[combined_df['ds'] <= '2024-06-30']\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'hotel_id' and count the number of rows for each hotel\n",
    "hotel_counts = combined_df.groupby('hotel_id').size()\n",
    "\n",
    "# Filter for hotels that have more than 92 rows\n",
    "hotels_with_more_than_30_rows = hotel_counts[hotel_counts > 30].index\n",
    "\n",
    "# Filter the original table for these hotels\n",
    "filtered_combined_df = combined_df[combined_df['hotel_id'].isin(hotels_with_more_than_30_rows)]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "filtered_combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_df.shape)\n",
    "print(filtered_combined_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_list = filtered_combined_df['hotel_id'].drop_duplicates()\n",
    "print(hotel_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the hotel list into 5 chunks based on the conditions you provided\n",
    "chunk_1 = hotel_list[hotel_list < 5000]\n",
    "chunk_2 = hotel_list[(hotel_list >= 5000) & (hotel_list < 10000)]\n",
    "chunk_3 = hotel_list[(hotel_list >= 10000) & (hotel_list < 12500)]\n",
    "chunk_4 = hotel_list[(hotel_list >= 12500) & (hotel_list < 13000)]\n",
    "chunk_5 = hotel_list[(hotel_list >= 13000) & (hotel_list < 13500)]\n",
    "chunk_6 = hotel_list[(hotel_list >= 13500) & (hotel_list < 14000)]\n",
    "chunk_7 = hotel_list[(hotel_list >= 14000) & (hotel_list < 14500)]\n",
    "chunk_8 = hotel_list[(hotel_list >= 14500) & (hotel_list < 14750)]\n",
    "chunk_9 = hotel_list[(hotel_list >= 14750) & (hotel_list < 15000)]\n",
    "chunk_10 = hotel_list[(hotel_list >= 15000) & (hotel_list < 17500)]\n",
    "chunk_11 = hotel_list[(hotel_list >= 17500) & (hotel_list < 20000)]\n",
    "chunk_12 = hotel_list[(hotel_list >= 20000) & (hotel_list < 25000)]\n",
    "\n",
    "\n",
    "# List of chunks to process\n",
    "chunks = [ chunk_1, chunk_2, chunk_3, chunk_4, chunk_5, chunk_6, chunk_7, chunk_8, chunk_9, chunk_10, chunk_11, chunk_12]\n",
    "\n",
    "# Loop through each chunk\n",
    "for idx, chunk in enumerate(chunks):\n",
    "    print(f\"Processing chunk {idx + 1} with {len(chunk)} hotels...\")\n",
    "\n",
    "    # Initialize an empty DataFrame to store all results for this chunk\n",
    "    all_forecasts_chunk = pd.DataFrame()\n",
    "\n",
    "    # Loop through each hotel in the current chunk\n",
    "    for hotel in chunk:\n",
    "        print(f\"Processing forecast for Hotel {hotel}...\")\n",
    "\n",
    "        # Load data for the specific hotel\n",
    "        hotel_data = combined_df[combined_df['hotel_id'].isin([hotel])]  # Define your function to get hotel data\n",
    "        \n",
    "        # Fit the model\n",
    "        model = Prophet()\n",
    "        model.fit(hotel_data)\n",
    "\n",
    "        # Create future dataframe for predictions\n",
    "        future = model.make_future_dataframe(periods=365)  # Forecast 1 year ahead\n",
    "\n",
    "        # Make predictions\n",
    "        forecast = model.predict(future)\n",
    "\n",
    "        # Add hotel name for identification\n",
    "        forecast[\"hotel\"] = hotel\n",
    "        \n",
    "        # Mark historical vs. forecasted data\n",
    "        forecast[\"data_type\"] = [\"historical\" if date <= hotel_data[\"ds\"].max() else \"forecast\" for date in forecast[\"ds\"]]\n",
    "\n",
    "        # Append to the main DataFrame for this chunk\n",
    "        all_forecasts_chunk = pd.concat([all_forecasts_chunk, forecast], ignore_index=True)\n",
    "\n",
    "    # Save the results for this chunk to a CSV file\n",
    "    all_forecasts_chunk.to_csv(f\"../out/hotel_forecasts_chunk_{idx + 1}.csv\", index=False)\n",
    "    \n",
    "    print(f\"Chunk {idx + 1} forecasting complete. Results saved as 'hotel_forecasts_chunk_{idx + 1}.csv'.\")\n",
    "\n",
    "print(\"All chunks processed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
